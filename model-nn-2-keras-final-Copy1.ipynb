{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification using a neural network\n",
    "\n",
    "Here we adopt a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13501108782085776789\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3137627750\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4215924836951942508\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.read_csv('model/1129-fixed-data-matrix-karlgren.csv').set_index('character')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('hypothesized_phonetic_series.json', encoding='utf8') as f:\n",
    "    js = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15250, 4097)\n",
      "(15250, 981)\n"
     ]
    }
   ],
   "source": [
    "def getps(char):\n",
    "    if char in js:\n",
    "        return js[char]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def rowIndex(row):\n",
    "    return getps(row.name)\n",
    "\n",
    "matrix['ps'] = matrix.apply(rowIndex, axis=1)\n",
    "\n",
    "one_hot = pd.get_dummies(matrix['ps'], prefix = 'ps')\n",
    "dropval = 3\n",
    "print(one_hot.shape)\n",
    "one_hot.drop([col for col, val in one_hot.sum().iteritems() if val < dropval], axis=1, inplace=True)\n",
    "print(one_hot.shape)\n",
    "\n",
    "matrix = matrix.drop('ps', axis = 1)\n",
    "\n",
    "matrix = matrix.join(one_hot)\n",
    "matrix.columns\n",
    "matrix.to_csv(\"out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = matrix.columns\n",
    "features_cols = [c for c in cols if 'Karlgren' not in c and 'tone_label' not in c]\n",
    "labels_cols = [c for c in cols if c not in features_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_complete = matrix[features_cols]\n",
    "Y_complete = matrix[labels_cols]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_complete, Y_complete, test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_categories = [\n",
    "    ('tone_label', \n",
    "     (\n",
    "        (32, 'relu'),\n",
    "        (16, 'relu'),\n",
    "     ),\n",
    "     10\n",
    "    ),\n",
    "    ('Karlgren_onset',\n",
    "     (\n",
    "        (768, 'relu'),\n",
    "        (0.8, 'dropout'),\n",
    "        (192, 'relu'),\n",
    "     ),\n",
    "     20\n",
    "    ),\n",
    "    ('Karlgren_nucleus',\n",
    "     (\n",
    "        (1024, 'relu'),\n",
    "        (0.8, 'dropout'),\n",
    "        (192, 'relu'),\n",
    "     ),\n",
    "     20\n",
    "    ),\n",
    "    ('Karlgren_coda',\n",
    "     (\n",
    "        (96, 'relu'),\n",
    "        (24, 'relu'),\n",
    "     ),\n",
    "     10\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_keras_models(X, X_test, Y, Y_test):\n",
    "    category_to_performance = defaultdict(list)\n",
    "    category_to_test_performance = defaultdict(list)\n",
    "    category_to_callbacks = defaultdict(list)\n",
    "    \n",
    "    for category, architecture, num_epochs in label_categories:\n",
    "        print(\"======= Starting training for \" + category + \" =======\")\n",
    "\n",
    "        Y_subset = Y[[x for x in Y.columns if category in x]]\n",
    "        Y_test_subset = Y_test[[x for x in Y_test.columns if category in x]]\n",
    "        n_bins = Y_subset.shape[1]\n",
    "        \n",
    "        def build_keras_nn_model():\n",
    "            model = Sequential()\n",
    "            model.add(Dense(\n",
    "                architecture[0][0],\n",
    "                input_dim=X.shape[1],\n",
    "                activation=architecture[0][1])\n",
    "            )\n",
    "            \n",
    "            if len(architecture) > 1:\n",
    "                for l, (hidden_layer_size, act_fn) in enumerate(architecture[1:]):\n",
    "                    if act_fn is 'dropout':\n",
    "                        model.add(Dropout(\n",
    "                            rate=hidden_layer_size\n",
    "                        ))\n",
    "                    else:\n",
    "                        model.add(Dense(\n",
    "                            hidden_layer_size,\n",
    "                            input_dim=architecture[l - 1],\n",
    "                            activation=act_fn)\n",
    "                        )\n",
    "                    \n",
    "            model.add(Dense(n_bins, activation='softmax'))\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            return model\n",
    "        \n",
    "        KerasNN = KerasClassifier(\n",
    "            build_fn=build_keras_nn_model,\n",
    "            epochs=num_epochs,\n",
    "            batch_size=256,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        X_train = X\n",
    "        Y_train = Y_subset\n",
    "\n",
    "        hist_callback = KerasNN.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "        )\n",
    "\n",
    "        category_to_callbacks[category].append(hist_callback)\n",
    "        test_acc = KerasNN.score(X_test, Y_test_subset)\n",
    "        category_to_test_performance[category].append(test_acc)\n",
    "        print('Test performance: {:.3f}'.format(float(test_acc)))\n",
    "        print('\\n\\n')\n",
    "    return category_to_performance, category_to_callbacks, category_to_test_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Starting training for tone_label =======\n",
      "Epoch 1/10\n",
      "10698/10698 [==============================] - 2s 226us/step - loss: 1.2534 - acc: 0.4459\n",
      "Epoch 2/10\n",
      "10698/10698 [==============================] - 1s 49us/step - loss: 0.8903 - acc: 0.6983\n",
      "Epoch 3/10\n",
      "10698/10698 [==============================] - 1s 51us/step - loss: 0.6344 - acc: 0.7934\n",
      "Epoch 4/10\n",
      "10698/10698 [==============================] - 1s 49us/step - loss: 0.5298 - acc: 0.8090\n",
      "Epoch 5/10\n",
      "10698/10698 [==============================] - 1s 50us/step - loss: 0.4893 - acc: 0.8192\n",
      "Epoch 6/10\n",
      "10698/10698 [==============================] - 1s 50us/step - loss: 0.4650 - acc: 0.8312\n",
      "Epoch 7/10\n",
      "10698/10698 [==============================] - 1s 60us/step - loss: 0.4472 - acc: 0.8375: 0s - loss: 0.4504 - acc: 0\n",
      "Epoch 8/10\n",
      "10698/10698 [==============================] - 1s 63us/step - loss: 0.4323 - acc: 0.8440\n",
      "Epoch 9/10\n",
      "10698/10698 [==============================] - 1s 62us/step - loss: 0.4192 - acc: 0.8474: 0s - loss: 0.4106 - acc: 0\n",
      "Epoch 10/10\n",
      "10698/10698 [==============================] - 1s 64us/step - loss: 0.4070 - acc: 0.8503: 0s - loss: 0.4455 - \n",
      "4586/4586 [==============================] - 1s 255us/step\n",
      "Test performance: 0.811\n",
      "\n",
      "\n",
      "\n",
      "======= Starting training for Karlgren_onset =======\n",
      "Epoch 1/20\n",
      "10698/10698 [==============================] - 5s 431us/step - loss: 2.8877 - acc: 0.2812\n",
      "Epoch 2/20\n",
      "10698/10698 [==============================] - 1s 77us/step - loss: 1.5387 - acc: 0.5838\n",
      "Epoch 3/20\n",
      "10698/10698 [==============================] - 1s 74us/step - loss: 1.1606 - acc: 0.6728\n",
      "Epoch 4/20\n",
      "10698/10698 [==============================] - 1s 80us/step - loss: 1.0116 - acc: 0.7144\n",
      "Epoch 5/20\n",
      "10698/10698 [==============================] - 1s 111us/step - loss: 0.9192 - acc: 0.7390\n",
      "Epoch 6/20\n",
      "10698/10698 [==============================] - 1s 89us/step - loss: 0.8671 - acc: 0.7557\n",
      "Epoch 7/20\n",
      "10698/10698 [==============================] - 1s 74us/step - loss: 0.8208 - acc: 0.7669\n",
      "Epoch 8/20\n",
      "10698/10698 [==============================] - 1s 74us/step - loss: 0.7875 - acc: 0.7713\n",
      "Epoch 9/20\n",
      "10698/10698 [==============================] - 1s 73us/step - loss: 0.7412 - acc: 0.7841: 0s - loss: 0.7425 - \n",
      "Epoch 10/20\n",
      "10698/10698 [==============================] - 1s 78us/step - loss: 0.7111 - acc: 0.7915: 0s - loss: 0.7364 - \n",
      "Epoch 11/20\n",
      "10698/10698 [==============================] - 1s 89us/step - loss: 0.6881 - acc: 0.7979\n",
      "Epoch 12/20\n",
      "10698/10698 [==============================] - 1s 106us/step - loss: 0.6607 - acc: 0.8022\n",
      "Epoch 13/20\n",
      "10698/10698 [==============================] - 2s 142us/step - loss: 0.6328 - acc: 0.8109\n",
      "Epoch 14/20\n",
      "10698/10698 [==============================] - 1s 99us/step - loss: 0.6120 - acc: 0.8135\n",
      "Epoch 15/20\n",
      "10698/10698 [==============================] - 1s 105us/step - loss: 0.5976 - acc: 0.8170\n",
      "Epoch 16/20\n",
      "10698/10698 [==============================] - 1s 82us/step - loss: 0.5789 - acc: 0.8203\n",
      "Epoch 17/20\n",
      "10698/10698 [==============================] - 1s 74us/step - loss: 0.5612 - acc: 0.8248\n",
      "Epoch 18/20\n",
      "10698/10698 [==============================] - 1s 73us/step - loss: 0.5464 - acc: 0.8322\n",
      "Epoch 19/20\n",
      "10698/10698 [==============================] - 1s 75us/step - loss: 0.5285 - acc: 0.8344\n",
      "Epoch 20/20\n",
      "10698/10698 [==============================] - 1s 73us/step - loss: 0.5054 - acc: 0.8402\n",
      "4586/4586 [==============================] - 1s 296us/step\n",
      "Test performance: 0.763\n",
      "\n",
      "\n",
      "\n",
      "======= Starting training for Karlgren_nucleus =======\n",
      "Epoch 1/20\n",
      "10698/10698 [==============================] - 4s 327us/step - loss: 3.2997 - acc: 0.2177\n",
      "Epoch 2/20\n",
      "10698/10698 [==============================] - 1s 81us/step - loss: 1.9037 - acc: 0.5268\n",
      "Epoch 3/20\n",
      "10698/10698 [==============================] - 1s 76us/step - loss: 1.3802 - acc: 0.6260\n",
      "Epoch 4/20\n",
      "10698/10698 [==============================] - 1s 79us/step - loss: 1.1742 - acc: 0.6827\n",
      "Epoch 5/20\n",
      "10698/10698 [==============================] - 1s 80us/step - loss: 1.0429 - acc: 0.7090\n",
      "Epoch 6/20\n",
      "10698/10698 [==============================] - 1s 90us/step - loss: 0.9568 - acc: 0.7312\n",
      "Epoch 7/20\n",
      "10698/10698 [==============================] - 1s 118us/step - loss: 0.8996 - acc: 0.7514\n",
      "Epoch 8/20\n",
      "10698/10698 [==============================] - 1s 126us/step - loss: 0.8322 - acc: 0.7687\n",
      "Epoch 9/20\n",
      "10698/10698 [==============================] - 1s 121us/step - loss: 0.7792 - acc: 0.7762\n",
      "Epoch 10/20\n",
      "10698/10698 [==============================] - 1s 102us/step - loss: 0.7437 - acc: 0.7909\n",
      "Epoch 11/20\n",
      "10698/10698 [==============================] - 1s 90us/step - loss: 0.7022 - acc: 0.8014\n",
      "Epoch 12/20\n",
      "10698/10698 [==============================] - 1s 83us/step - loss: 0.6783 - acc: 0.8032: 0s - loss: 0.6825 - acc: \n",
      "Epoch 13/20\n",
      "10698/10698 [==============================] - 1s 82us/step - loss: 0.6336 - acc: 0.8130: 0s - loss: 0.6145 -\n",
      "Epoch 14/20\n",
      "10698/10698 [==============================] - 1s 89us/step - loss: 0.6202 - acc: 0.8161: 0s - loss: 0.6173 - acc: 0.820 - ETA: 0s - loss: 0.6126 - ac\n",
      "Epoch 15/20\n",
      "10698/10698 [==============================] - 1s 86us/step - loss: 0.5964 - acc: 0.8208\n",
      "Epoch 16/20\n",
      "10698/10698 [==============================] - 1s 84us/step - loss: 0.5740 - acc: 0.8281\n",
      "Epoch 17/20\n",
      "10698/10698 [==============================] - 1s 85us/step - loss: 0.5558 - acc: 0.8316\n",
      "Epoch 18/20\n",
      "10698/10698 [==============================] - 1s 80us/step - loss: 0.5361 - acc: 0.8419\n",
      "Epoch 19/20\n",
      "10698/10698 [==============================] - 1s 74us/step - loss: 0.5164 - acc: 0.8437\n",
      "Epoch 20/20\n",
      "10698/10698 [==============================] - 1s 71us/step - loss: 0.5035 - acc: 0.8454\n",
      "4586/4586 [==============================] - 1s 263us/step\n",
      "Test performance: 0.750\n",
      "\n",
      "\n",
      "\n",
      "======= Starting training for Karlgren_coda =======\n",
      "Epoch 1/10\n",
      "10698/10698 [==============================] - 3s 295us/step - loss: 1.5384 - acc: 0.6374\n",
      "Epoch 2/10\n",
      "10698/10698 [==============================] - 1s 57us/step - loss: 0.5439 - acc: 0.8833\n",
      "Epoch 3/10\n",
      "10698/10698 [==============================] - 1s 53us/step - loss: 0.3113 - acc: 0.9297\n",
      "Epoch 4/10\n",
      "10698/10698 [==============================] - 1s 54us/step - loss: 0.2400 - acc: 0.9388\n",
      "Epoch 5/10\n",
      "10698/10698 [==============================] - 1s 60us/step - loss: 0.2044 - acc: 0.9455: 0s - loss: 0.1884 - ac\n",
      "Epoch 6/10\n",
      "10698/10698 [==============================] - 1s 64us/step - loss: 0.1816 - acc: 0.9512\n",
      "Epoch 7/10\n",
      "10698/10698 [==============================] - 1s 61us/step - loss: 0.1657 - acc: 0.9537\n",
      "Epoch 8/10\n",
      "10698/10698 [==============================] - 1s 57us/step - loss: 0.1520 - acc: 0.9565\n",
      "Epoch 9/10\n",
      "10698/10698 [==============================] - 1s 62us/step - loss: 0.1403 - acc: 0.9581\n",
      "Epoch 10/10\n",
      "10698/10698 [==============================] - 1s 57us/step - loss: 0.1318 - acc: 0.9601\n",
      "4586/4586 [==============================] - 1s 228us/step\n",
      "Test performance: 0.939\n",
      "\n",
      "\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "performance, callbacks, test_performance = fit_keras_models(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    ")\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'tone_label': [0.8113824690578808],\n",
       "             'Karlgren_onset': [0.7634103787657583],\n",
       "             'Karlgren_nucleus': [0.7503270832305905],\n",
       "             'Karlgren_coda': [0.9387265578191768]})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
